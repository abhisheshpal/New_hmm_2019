#! /usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on: Day Mon DD HH:MM:SS YYYY

@author: marc-hanheide
@author: abhisheshpal
@author: gpdas
"""


#==============================================================================
#
#==============================================================================
import numpy as np
import matplotlib.pyplot as plt
import hmms
from pprint import pformat

#%matplotlib inline
#%config InlineBackend.figure_format = 'svg'


class HMModel(object):
    """
    """
    def __init__(self, n_states, from_file, f_name=None, trans_rate_mat=None, obs_prob_mat=None, init_state_prob=None):
        """
        Keywork arguments:

        trans_rate_mat -- transition rate marix, (n_states x n_states)
        obs_prob_mat -- observation probability matrix,
                        it indicates given an observation what is the probability that it is correct,
                        (n_states x n_states+1) additional state as a means for querying
        init_state_prob -- array of initial state probabilities, (n_states)
        """
        self.n_states = n_states        
        if from_file:
            assert f_name is not None
            # create CtHMM from file
            self.from_file(f_name)
        else:
            assert trans_rate_mat is not None
            assert obs_prob_mat is not None
            assert init_state_prob is not None
            # Create CtHMM by given parameters
            self._model = hmms.CtHMM(trans_rate_mat, obs_prob_mat, init_state_prob)
        print('Q=%s,\nB=%s,\nPi=%s' % self._model.chmm.params)

    def from_file(self, f_name):
        """Load model object from a file
        Set & Get Parameters:Later you can always set parameters with triple of methods corresponding to the constructors.
        chmm.set_params(Q,B,Pi)
        chmm.set_params_random(3,3)
        chmm.set_params_from_file( "state2_cthmm.npz" )
        """
        self._model = hmms.CtHMM.from_file(f_name)
    
    def to_file(self, f_name):
        self._model.save_params(f_name)
    
    def generate_random(self, sample_len, sample_step, verbose=False):
        """generates predictions from a random initial state (decided based on the state probs)
        """
        # sample uniformly
        t_seq = range(0,sample_len, sample_step)
        t_seq, s_seq, e_seq = self._model.generate(len(t_seq), time=t_seq)
    
        #resize plot
        plt.rcParams['figure.figsize'] = [20,20]
    
        hmms.plot_hmm(s_seq, e_seq, time=t_seq )
        if verbose:
            print(t_seq)

        return (t_seq, s_seq, e_seq)

    def predict(self, obs=np.array([0,1,2,3,4]), predict_time=20.0, verbose=False):
        """
        """
        # now let's try some prediction, define the predict function
        # we will take n observation states

        # observations so far (this is where we have seen people being in a place at a specific time):
        e_seq = np.array(obs)
        # assume the observations were made 1 second apart
        t_seq = np.array(range(0,len(e_seq)+1))

        # Now the predict step
        # the last observation codes for unknown,"abusing" the Viterbi algorithm to provide predictions
        # purely on the transition model
        e_seq[-1:] = self.n_states

        # this is the look ahead time (i.e. the time we look into the future based on the last observation)
        predict_time = 1.2

        # set the last "unknown" observation time:
        t_seq[-1] = t_seq[-2] + predict_time

        if verbose: 
            print(t_seq, e_seq)

        # run Viterbi algorithm for the CtHMM
        (log_prob, s_seq) =  self._model.viterbi( t_seq, e_seq )

        # We can also query the state distribution for the entire sequence
        log_prob_table = self._model.states_confidence( t_seq, e_seq )
        post_distribution = np.exp( log_prob_table[-1] )

        if verbose:
            # Let's print the most likely state sequence
            hmms.plot_hmm( s_seq, e_seq, time = t_seq )
            print( "found state sequence: \n", s_seq )
            print( "predicted state looking %f seconds into the future: %d" % (predict_time, s_seq[-1]) )
            print( "Probability of being generated by the found state sequence:", np.exp( log_prob ) )
            print( "state probs: \n", post_distribution)

        uniform = np.array([1.0 / self.n_states] * self.n_states)   # get the 1 X N_nodes matrix of uniform distribution

        # Now KL divergence is used to get the difference between the two distributions--
        # (here btween uniform and post_distribution) and is denoted by D_KL = (post_distribution || uniform) =
        # itergral of (p(x)* log((px)/q(x))
        # KL divergence: https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Basic_example
        # KL can be used here as a measure of certainty to some extend, used to compare against uniform distribution,
        # the longer into the future the prediction, the closer KL is to 0
        D_KL = np.sum(np.multiply(post_distribution, np.log(np.divide(post_distribution, uniform))))
        if verbose: 
            print("Kullbackâ€“Leibler divergence (high is good in this case, as I compare against uniform): %f" % D_KL)

        return (s_seq[-1], D_KL, post_distribution)

    def check_prediction_probs(self, obs, forecast_max, forecast_steps, verbose=False):
        """
        Keyword arguments:
        
        obs -- initial observations
        forecast_max -- max time to forecast
        forecast_steps -- time steps to be taken to reach forecast_max
        """
    
        posteriors = []
        states = {}
        kls = []
        times = []
    
        # try forecasting for several time steps:
        for i in np.linspace(1, forecast_max, forecast_steps):  # Return evenly spaced numbers over a specified interval (start,stop, Num = int).
            (state, kl, posterior) = self._model.predict(
                                                         obs,
                                                         predict_time = i,
                                                         verbose = False
                                                         )
            times.append(i)
            posteriors.append(posterior)
            states[i] = state
            kls.append(kl)
    
        # plot the posterior probabilities
        plt.plot(times, posteriors, '-x')
    
        # plot the KL divergence (certainty)
        plt.plot(times, kls, linewidth=3)
    
        legend = list(range(0, self.n_states))
        legend.append('KL')
        plt.legend(legend)
        plt.show()
        
        if verbose:
            print('state predictions:\n%s' % pformat(states))
        
        return times, states, kls, posteriors
    


if __name__ == "__main__":

#==============================================================================
# mode model
#==============================================================================
    #STEP 1: Create a model of sequences with prior known(randomly generated) transition matrix,
            # emmision probability, and initial state prob.vector

    n_states = 5 #number of picker modes

    # defining a very simple state map 
    state_map = np.eye(n_states, k=1) # create identity matrix with N_nodes rows with diagonal element as 1.
    state_map[-1,1] = 1                 # replace last row, first column element with 1
    state_map[2,0] = 0.142
    state_map[2,-2] = 0.857

    print (state_map)
    
    # reversing not needed for modes
        
    # summing all column of adjency matrix
    rs = np.sum(state_map, 1)       # it sums up all the columns of a single row,
                                  #so that it can help in defining Q in next step

    # creating the transition rate matrix (https://en.wikipedia.org/wiki/Transition_rate_matrix)
    # TODO: transition rates are not constant across the modes 
    # expected mean rate in seconds
    _rate = 5.0
    _lambda = 1.0/_rate
    Q = (np.diag(-rs) + state_map) * _lambda   # Keep in mind that, sum(Qij) = -Qii =< 1.

    # creating observation matrix, assuming each states has ~70% prob to emit the state itself as observation
    # and another ~10% for neighbouring states each (confusing them). and +.1% for all observations
    # for numerical stability
    # TODO: these observation probabilities are also absurd as of now
    B_pre = np.ones(n_states) * .001 + np.eye(n_states) * .7 + np.eye(n_states, k=1) * .1 + np.eye(n_states, k=-1) * .1

    # adding 10% change of "unknown" observation which each state is equally likely to emit (used for prediction)
    # This assumption can be eliminated
    B = np.transpose(np.vstack([B_pre, [.101] * n_states]))  # np.vstack will add extra column in B_pre matrix
                                                            # vertically
    B[0,-2] = .101     # first row and second last column is filled with 0.101
    B[-1,0] = .101     # Last row and first columm is filled with 0.101


    # normalise B (make sure probs sum up to 1)
    row_sums = B.sum(axis=1)
    B = B / row_sums[:, np.newaxis]

    # Pi is the vector of initial state probabilities. Assuming uniform here
    # (We may make a stronger assumption here at some point)
    Pi = np.array([1.0 / n_states] * n_states )   # We need to change Pi based on des data as Pi = [0.03, 0.26, 0.23, 0.23, 0.23]

    # Create CtHMM by given parameters.
    mode_model = HMModel(n_states, False, None, Q, B, Pi)
    # save model
    mode_model.to_file("mode_model")
    # load model from file
#    mode_model = HMModel(N_nodes, True, "mode_model.npz")

    # sample a random sequence within desired time peroiod from the above created model(for testing and generation)
    t_seq, s_seq, e_seq = mode_model.generate_random(sample_len=60, sample_step=2)

    # predict for a specific time from an initial observation
    (state, KL, posteriors) = mode_model.predict(
                                                 # start with some observations assumed to have made up to a point
                                                 obs=np.array([0,1,2,3,4]),
                                                 # the time horizon to predict to
                                                 predict_time=60,
                                                 # we want to see stuff here
                                                 verbose=True
                                                 )

    # forecast max seconds
    times, states, kls, posteriors = mode_model.check_prediction_probs(obs=[0,1,2,3,4], forecast_max=60., forecast_steps=60, verbose=True)

# The modex_node_models below model the transition of the pickers along the topological map, and could be used
# to predict the node at which the picker would be, from an initial observation.
# these models should be similar to the mode_model section above, using the HMModel class

#==============================================================================
# mode0_node_model
#==============================================================================


#==============================================================================
# mode1_node_model
#==============================================================================
    

#==============================================================================
# mode2_node_model
#==============================================================================
    

#==============================================================================
# mode3_node_model
#==============================================================================
   
#==============================================================================
# mode4_node_model
#==============================================================================
   

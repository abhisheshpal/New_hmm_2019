# -*- coding: utf-8 -*-
"""
Spyder Editor

This is a temporary script file.
"""

#!/usr/bin/python
# -*- coding: utf-8 -*-
"""
Created on: Day Mon DD HH:MM:SS YYYY

@author: marc-hanheide
@author: abhisheshpal
@author: gpdas
"""

"""
Sequence of hmm models in this script
- class HMModel
- FORWARD PICKING prediction model of MODE 2 within SUBSTATEs 
- FORWARD PICKING : mode2_node_model
- BACKWARD PICKING : mode2_node_model

"""

#==============================================================================
#
#==============================================================================
import numpy as np
import matplotlib.pyplot as plt
import hmms
from pprint import pformat
import sys
import operator
import os

#%matplotlib inline
#%config InlineBackend.figure_format = 'svg'

np.set_printoptions(threshold=sys.maxsize)

class HMModel(object):
    """
    """
    def __init__(self, n_states, from_file, f_name=None, trans_rate_mat=None, obs_prob_mat=None, init_state_prob=None):
        """
        Keywork arguments:

        trans_rate_mat -- transition rate marix, (n_states x n_states)
        obs_prob_mat -- observation probability matrix,
                        it indicates given an observation what is the probability that it is correct,
                        (n_states x n_states+1) additional state as a means for querying
        init_state_prob -- array of initial state probabilities, (n_states)
        """
        self.n_states = n_states
        if from_file:
            assert f_name is not None
            # create CtHMM from file
            self.from_file(f_name)
        else:
            assert trans_rate_mat is not None
            assert obs_prob_mat is not None
            assert init_state_prob is not None
            # Create CtHMM by given parameters
            self._model = hmms.CtHMM(trans_rate_mat, obs_prob_mat, init_state_prob)
        print('Q=%s,\nB=%s,\nPi=%s' % self._model.params)

    def from_file(self, f_name):
        """Load model object from a file
        Set & Get Parameters:Later you can always set parameters with triple of methods corresponding to the constructors.
        chmm.set_params(Q,B,Pi)
        chmm.set_params_random(3,3)
        chmm.set_params_from_file( "state2_cthmm.npz" )
        """
        self._model = hmms.CtHMM.from_file(f_name)

    def to_file(self, f_name):
        """save cthmm model to a npz file
        """
        self._model.save_params(f_name)

    def generate_random(self, sample_len, sample_step , verbose=False):
        """generates predictions from a random initial state (decided based on the state probs)
        """
        # sample uniformly
        t_seq = range(0,sample_len, sample_step)

        t_seq, s_seq, e_seq = self._model.generate(len(t_seq), time=t_seq)

#        #resize plot
        plt.rcParams['figure.figsize'] = [20,20]
#
        hmms.plot_hmm(s_seq, e_seq, time=t_seq )
        if verbose:
            print('t_seq',t_seq)

        return (t_seq, s_seq, e_seq)

    def predict(self, obs=np.array([0,1,2,3,4]), predict_time=20.0, verbose=False):
        """
        """
        # now let's try some prediction, define the predict function
        # we will take n observation states

        # observations so far (this is where we have seen people being in a place at a specific time):
        e_seq = np.array(obs)
        # assume the observations were made 1 second apart
        t_seq = np.array(range(0,len(e_seq)))

        # Now the predict step
        # the last observation codes for unknown,"abusing" the Viterbi algorithm to provide predictions
        # purely on the transition model
        e_seq[-1:] = self.n_states

        # this is the look ahead time (i.e. the time we look into the future based on the last observation)
        #predict_time = 50

        # set the last "unknown" observation time:
        t_seq[-1] = t_seq[-2] + predict_time

        if verbose:
            print('t_seq, e_seq', t_seq, e_seq)

        # run Viterbi algorithm for the CtHMM
        (log_prob, s_seq) =  self._model.viterbi( t_seq, e_seq )

        # We can also query the state distribution for the entire sequence
        log_prob_table = self._model.states_confidence( t_seq, e_seq )
        post_distribution = np.exp( log_prob_table[-1] )

        if verbose:
            # Let's print the most likely state sequence
            hmms.plot_hmm( s_seq, e_seq, time = t_seq )
            print( "found state sequence: \n", s_seq )
            print( "predicted state looking %f seconds into the future: %d" % (predict_time, s_seq[-1]) )
            print( "Probability of being generated by the found state sequence:", np.exp( log_prob ) )
#            print( "state probs: \n", post_distribution)

        uniform = np.array([1.0 / self.n_states] * self.n_states)   # get the 1 X N_nodes matrix of uniform distribution
        # Now KL divergence is used to get the difference between the two distributions--
        # (here btween uniform and post_distribution) and is denoted by D_KL = (post_distribution || uniform) =
        # itergral of (p(x)* log((px)/q(x))
        # KL divergence: https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Basic_example
        # KL can be used here as a measure of certainty to some extend, used to compare against uniform distribution,
        # the longer into the future the prediction, the closer KL is to 0
        D_KL = np.sum(np.multiply(post_distribution, np.log(np.divide(post_distribution, uniform))))

        if verbose:
            print( "Kullbackâ€“Leibler divergence (high is good in this case, as I compare against uniform): %f" % (D_KL) )
        return (s_seq[-1], D_KL, post_distribution)

    def check_prediction_probs(self, obs, forecast_max, forecast_steps, verbose=False):
        """
        Keyword arguments:

        obs -- initial observations
        forecast_max -- max time to forecast
        forecast_steps -- time steps to be taken to reach forecast_max
        """
        posteriors = []
        states = {}
        kls = []
        times = []

        # try forecasting for several time steps:
        for i in np.linspace(1, forecast_max, forecast_steps):  # Return evenly spaced numbers over a specified interval (start,stop, Num = int).
            (state, kl, posterior) = self.predict(
                                                         obs,
                                                         predict_time = i,
                                                         verbose = False
                                                         )
            times.append(i)
            posteriors.append(posterior)
            states[i] = state
            kls.append(kl)

#         plot the posterior probabilities
        plt.plot(times, posteriors, '-x')

#         plot the KL divergence (certainty)
        plt.plot(times, kls, linewidth=3)

        legend = list(range(0, self.n_states))
        legend.append('KL')
        plt.legend(legend)
        plt.show()

        if verbose:
            print('state predictions:\n%s' % pformat(states))

        return times, states, kls, posteriors



if __name__ == "__main__":

#==============================================================================
# prediction model of MODE 2 within SUBSTATEs 
#==============================================================================

    n_states = 6  # States decided based on transitions within susbtates as 2(0),2(0)-> 2(1), ..., 2(6).  
    _rate = 0.00206 #0.0005
    state_map = np.eye(n_states, k=1) # connect all the successive substates in forward direction
    state_map[-1,0] = 1  
    state_map += np.eye(n_states, k=-1)*0.1 # connect all the successive sustates in backward direction
    state_map[0,-1] = 0.1  
    print ('\n FORWARD PICKING prediction model of MODE 2 within SUBSTATEs \n')
    rs = np.sum(state_map,1)

    Q = (np.diag(-rs) + state_map)*_rate
    # creating observation matrix, assuming each states has ~70% prob to emit the state itself as observation
    # and another ~10% for neighbouring states each (confusing them). and +.1% for all observations
    # for numerical stability
    B_pre = np.ones(n_states) * .001 + np.eye(n_states) * .7 + np.eye(n_states, k=1) * .1 + np.eye(n_states, k=-1) * .1
    
    # adding 10% change of "unknown" observation which each state is equally likely to emit (used for prediction)
    B = np.transpose(np.vstack([B_pre, [.101] * n_states]))  # np.vstack will add extra column in B_pre matrix vertically

    B[0,-2] = .101     # first row and second last column is filled with 0.101
    B[-1,0] = .101     # Last row and first columm is filled with 0.101

    # normalise B (make sure probs sum up to 1)
    row_sums = B.sum(axis=1)
    B = B / row_sums[:, np.newaxis]

    # Pi is the vector of initial state probabilities. Assuming uniform here
    # (We may make a stronger assumption here at some point)
    Pi = np.array([1.0 / n_states] * n_states )   # Uniform Pi for all substates
#    Pi = np.array([0., 1.0, 0.0, 0.0, 0.0 , 0.0]) # Non-Uniform Pi


    # Create CtHMM by given parameters.
    mode_model = HMModel(n_states, False, None, Q, B, Pi)
    # save model
    mode_model.to_file("mode_model")
    # load model from file
    mode_model = HMModel(n_states, True, "mode_model.npz")

    # sample a random sequence within desired time peroiod from the above created model(for testing and generation)
    t_seq, s_seq, e_seq = mode_model.generate_random(sample_len=3000, sample_step=1)


    #print(s_seq)

    # predict for a specific time from an initial observation
    (state, KL, posteriors) = mode_model.predict(
                                                 # start with some observations assumed to have made up to a point
                                                 obs=np.array([2,3,4]),
                                                 # the time horizon to predict to
                                                 predict_time=1700,
                                                 # we want to see stuff here
                                                 verbose=True
                                                 )

    # forecast max seconds
    times, states, kls, posteriors = mode_model.check_prediction_probs(obs=[2,3,4], forecast_max=3000, forecast_steps=100, verbose=True)
    print (sorted(states.items(), key=operator.itemgetter(0)))


# The modex_node_models below model the transition of the pickers along the topological map(nodes), and could be used
# to predict the node at which the picker would be, from an initial observation.
# these models should be similar to the mode_model section above, using the HMModel class

#==============================================================================
# FORWARD PICKING : mode2_node_model
#==============================================================================

#State2 consists of several node transition in a unidirectional way in forward direction:

    n_states = 196  #number of nodes considered (2 ROW with 96 row_nodes each and 1, 1 head_nodes and sec_nodes, hence each ROW = 100 nodes)
                    # Each row is paralle yet in a cyclic pattern as (HOW TOPO_MAP LOOKS like :  ---><pri-hn-00 ---><--- 1---><---2..
                    # --><--96 ---><---sec-hn-00---><---sec-hn-01....  ---><--- rn-01-01---><---rn-01-00 ---><---pri-hn-01---><pri-hn-00.
    # Hence the idea is to create two identity matrices and concatenate it also keep the cyclic pattern by joining first and last node
    # defining a very simple state map -- Here state map = topo_node pattern.

    state_map = np.eye(n_states, k=1) # forward movement from row 1-->2 in a cyclic pattern (Counter Clock-Wise)
    state_map[97:99,97:99] = 0            # [ (total_rows/2)-1: (total_rows/2)+1 ] ; note: row count starts with 0
    state_map[98,0] = 1                   # connection between first node of first row and second node of second node in forward move [ (total_rows/2): 0]
    state_map[0,98] = 1                   # connection between first node of first row and second node of second node in reverse move [ 0: (total_rows/2)]


    state_map += np.eye(n_states, k=-1)*0.1  # reverse movement from row 2-->1 in a cyclic pattern (Clock-Wise)
    state_map[97:99,97:99] = 0               # [ (total_rows/2)-1: (total_rows/2)+1 ] ; note: row count starts with 0
    state_map[97,-1] = 1                     # connection between last node of first row and last node of second node in forward move.[(total_rows/2)-1: -1]
    state_map[-1,97] = 1                     #connection between first node of first row and second node of second node in reverse move.[-1: (total_rows/2)-1]
    print ('\n FORWARD PICKING : mode2_node_model \n')
#    print (state_map)


    # summing all column of adjency matrix
    rs = np.sum(state_map, 1)       # it sums up all the columns of a single row,so that it can help in defining Q in next step

    # creating the transition rate matrix (https://en.wikipedia.org/wiki/Transition_rate_matrix)
    # expected mean rate in seconds
    _rate =   0.001724078  # The rate is calculated from DES
    _lambda = _rate
#    _lambda = 1.0/_rate

    Q = (np.diag(-rs) + state_map) * _lambda   # Keep in mind that, sum(Qij) = -Qii =< 1.


    # MODE = 2
    # creating observation matrix based on DES data, each node has ~1.0% prob to emit the state itself as observation
    # and another ~97% for neighbouring nodes in forward direction and ~1% for neighbouring nodes in reverse direction each.
    # and +.1% for all observations for numerical stability

#    B_pre = np.ones(n_states) * .001 + np.eye(n_states) * .01 + np.eye(n_states, k=1) * .97 + np.eye(n_states, k=-1) * .01
    B_pre = np.ones(n_states) * .001 + np.eye(n_states) * .7 + np.eye(n_states, k=1) * .02 + np.eye(n_states, k=-1) * .02 + np.eye(n_states, k=2) * .01 + np.eye(n_states, k=-2) * .01


    B = np.transpose(np.vstack([B_pre, [.101] * n_states]))  # np.vstack will add extra column in B_pre matrix
                                                            # vertically
    B[0,-2] = .101     # first row and second last column is filled with 0.101

    B[-1,0] = .101     # Last row and first columm is filled with 0.101

    # normalise B (make sure probs sum up to 1)
    row_sums = B.sum(axis=1)
    B = B / row_sums[:, np.newaxis]
    # Pi is the vector of initial state probabilities. Assuming uniform here
    # (We may make a stronger assumption here at some point)
    Pi = np.array([1.0 / n_states] * n_states )   # Uniform Pi for all substates
#    Pi[168] = 1
    # Create CtHMM by given parameters.
    mode_model = HMModel(n_states, False, None, Q, B, Pi)
    # save model
    mode_model.to_file("mode_model")

    # load model from file
    mode_model = HMModel(n_states, True, "mode_model.npz")

    # sample a random sequence within desired time peroiod from the above created model(for testing and generation)
    t_seq, s_seq, e_seq = mode_model.generate_random(sample_len=2000, sample_step=1)

    # predict for a specific time from an initial observation
    (state, KL, posteriors) = mode_model.predict(
                                                 # start with some observations assumed to have made up to a point
                                                 obs=np.array([31,32,33]),
                                                 # the time horizon to predict to
                                                 predict_time=1500,
                                                 # we want to see stuff here
                                                 verbose=True
                                                 )

    # forecast max seconds
    times, states, kls, posteriors = mode_model.check_prediction_probs(obs=[31,32,33], forecast_max=3000., forecast_steps=200, verbose=True)
    print (sorted(states.items(), key=operator.itemgetter(0)))

#==============================================================================
# BACKWARD PICKING : mode2_node_model
#==============================================================================

#State2 consists of several node transition in a unidirectional way in backward direction:

    n_states = 196  #number of nodes considered (2 ROW with 96 row_nodes each and 1, 1 head_nodes and sec_nodes, hence each ROW = 100 nodes)
                    # Each row is paralle yet in a cyclic pattern as (HOW TOPO_MAP LOOKS like :  ---><pri-hn-00 ---><--- 1---><---2..
                    # --><--96 ---><---sec-hn-00---><---sec-hn-01....  ---><--- rn-01-01---><---rn-01-00 ---><---pri-hn-01---><pri-hn-00.
    # Hence the idea is to create two identity matrices and concatenate it also keep the cyclic pattern by joining first and last node
    # defining a very simple state map -- Here state map = topo_node pattern.

    state_map = np.eye(n_states, k=1)*0.1 # forward movement from row 1-->2 in a cyclic pattern (Counter Clock-Wise)
    state_map[97:99,97:99] = 0            # [ (total_rows/2)-1: (total_rows/2)+1 ] ; note: row count starts with 0
    state_map[98,0] = 1                   # connection between first node of first row and second node of second node in forward move [ (total_rows/2): 0]
    state_map[0,98] = 1                   # connection between first node of first row and second node of second node in reverse move [ 0: (total_rows/2)]


    state_map += np.eye(n_states, k=-1)  # reverse movement from row 2-->1 in a cyclic pattern (Clock-Wise)
    state_map[97:99,97:99] = 0               # [ (total_rows/2)-1: (total_rows/2)+1 ] ; note: row count starts with 0
    state_map[97,-1] = 1                     # connection between last node of first row and last node of second node in forward move.[(total_rows/2)-1: -1]
    state_map[-1,97] = 1                     #connection between first node of first row and second node of second node in reverse move.[-1: (total_rows/2)-1]
    print ('\n BACKWARD PICKING : mode2_node_model \n')
#    print (state_map)


    # summing all column of adjency matrix
    rs = np.sum(state_map, 1)       # it sums up all the columns of a single row,
                                  #so that it can help in defining Q in next step

    # creating the transition rate matrix (https://en.wikipedia.org/wiki/Transition_rate_matrix)
    # DONE : TODO: transition rates are not constant across the nodes hence need to be cal.
    # expected mean rate in seconds
    _rate =  0.001724078  #The rate is calculated from DES
    _lambda = _rate
#    _lambda = 1.0/_rate

    Q = (np.diag(-rs) + state_map) * _lambda   # Keep in mind that, sum(Qij) = -Qii =< 1.


    # MODE = 2
    # creating observation matrix based on DES data, each node has ~1.0% prob to emit the state itself as observation
    # and another ~97% for neighbouring nodes in forward direction and ~1% for neighbouring nodes in reverse direction each.
    # and +.1% for all observations for numerical stability

#    B_pre = np.ones(n_states) * .001 + np.eye(n_states) * .01 + np.eye(n_states, k=1) * .97 + np.eye(n_states, k=-1) * .01
    B_pre = np.ones(n_states) * .001 + np.eye(n_states) * .7 + np.eye(n_states, k=1) * .02 + np.eye(n_states, k=-1) * .02 + np.eye(n_states, k=2) * .01 + np.eye(n_states, k=-2) * .01


    B = np.transpose(np.vstack([B_pre, [.101] * n_states]))  # np.vstack will add extra column in B_pre matrix
                                                            # vertically
    B[0,-2] = .101     # first row and second last column is filled with 0.101

    B[-1,0] = .101     # Last row and first columm is filled with 0.101

    # normalise B (make sure probs sum up to 1)
    row_sums = B.sum(axis=1)
    B = B / row_sums[:, np.newaxis]
    # Pi is the vector of initial state probabilities. Assuming uniform here
    # (We may make a stronger assumption here at some point)
    Pi = np.array([1.0 / n_states] * n_states )   # Uniform Pi for all substates
#    Pi[168] = 1
    # Create CtHMM by given parameters.
    mode_model = HMModel(n_states, False, None, Q, B, Pi)
    # save model
    mode_model.to_file("mode_model")

    # load model from file
    mode_model = HMModel(n_states, True, "mode_model.npz")

    # sample a random sequence within desired time peroiod from the above created model(for testing and generation)
    t_seq, s_seq, e_seq = mode_model.generate_random(sample_len=5000, sample_step=1)

    # predict for a specific time from an initial observation
    (state, KL, posteriors) = mode_model.predict(
                                                 # start with some observations assumed to have made up to a point
                                                 obs=np.array([191,192,193]),
                                                 # the time horizon to predict to
                                                 predict_time=3000,
                                                 # we want to see stuff here
                                                 verbose=True
                                                 )

    # forecast max seconds
    times, states, kls, posteriors = mode_model.check_prediction_probs(obs=[191,192,193], forecast_max=3000., forecast_steps=200, verbose=True)
    print (sorted(states.items(), key=operator.itemgetter(0)))
